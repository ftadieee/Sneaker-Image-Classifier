{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from google.colab import files\n",
        "\n",
        "# --- STEP 1: FOLDER SETUP & DATA UPLOAD ---\n",
        "base_dir = 'MyShoesDataset'\n",
        "brands = ['Nike', 'Adidas', 'Puma']\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Create folders\n",
        "for brand in brands:\n",
        "    os.makedirs(os.path.join(base_dir, brand), exist_ok=True)\n",
        "\n",
        "# Dialogue boxes for each brand\n",
        "for brand in brands:\n",
        "    print(f\"\\n--- üëü UPLOAD 15-20 IMAGES FOR: {brand.upper()} ---\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dest_path = os.path.join(base_dir, brand, filename)\n",
        "        os.rename(filename, dest_path)\n",
        "    print(f\"‚úÖ Saved to {brand} folder.\")\n",
        "\n",
        "# --- STEP 2: DATA LOADING & PREPARATION ---\n",
        "print(\"\\n‚öôÔ∏è Preparing datasets...\")\n",
        "# We use 20% of your uploads for validation to check accuracy\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=4  # Small batch size is better for small datasets\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=4\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "# --- STEP 3: MODEL BUILDING & TRAINING ---\n",
        "print(\"\\nüß† Building and training model for 10 epochs...\")\n",
        "model = models.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=(224, 224, 3)),\n",
        "    # Data Augmentation helps when you only have a few images\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train for exactly 10 epochs as requested\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
        "print(\"‚úÖ Training Complete!\")\n",
        "\n",
        "# --- STEP 4: FINAL TESTING DIALOGUE ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"‚ú® TEST TIME! UPLOAD A FINAL SAMPLE IMAGE ‚ú®\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "test_upload = files.upload()\n",
        "\n",
        "for fn in test_upload.keys():\n",
        "    img = tf.keras.utils.load_img(fn, target_size=IMG_SIZE)\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    # Using argmax to find the brand with the highest percentage\n",
        "    result_idx = np.argmax(predictions[0])\n",
        "    predicted_brand = class_names[result_idx]\n",
        "    confidence = 100 * np.max(predictions[0])\n",
        "\n",
        "    print(\"\\n\" + \"-\"*30)\n",
        "    print(f\"üëü RESULT: This is {predicted_brand} shoes!\")\n",
        "    print(f\"üìä Confidence: {confidence:.2f}%\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "YLGS5YVIgrSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"‚ú® FINAL TEST: UPLOAD A SAMPLE IMAGE ‚ú®\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "test_upload = files.upload()\n",
        "\n",
        "for fn in test_upload.keys():\n",
        "    img = tf.keras.utils.load_img(fn, target_size=IMG_SIZE)\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    # Using argmax to find the brand with the highest percentage\n",
        "    result_idx = np.argmax(predictions[0])\n",
        "    predicted_brand = class_names[result_idx]\n",
        "    confidence = 100 * np.max(predictions[0])\n",
        "\n",
        "    print(\"\\n\" + \"-\"*30)\n",
        "    print(f\"üëü RESULT: This is {predicted_brand} shoes!\")\n",
        "    print(f\"üìä Confidence: {confidence:.2f}%\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "gMbL3_mfhAtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}